{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DesicionTree2.txt', 'DesicionTree47.txt', 'DesicionTree63.txt', 'GuassianNaiveBayes27.txt', 'GuassianNaiveBayes33.txt', 'GuassianNaiveBayes68.txt', 'KNearestNeighbors6.txt', 'KNearestNeighbors44.txt', 'KNearestNeighbors74.txt', 'MultilayerPerceptron16.txt', 'MultilayerPerceptron31.txt', 'MultilayerPerceptron74.txt', 'RandomForestClassifier13.txt', 'RandomForestClassifier44.txt', 'RandomForestClassifier85.txt', 'SupportVectorMachine14.txt', 'SupportVectorMachine53.txt', 'SupportVectorMachine76.txt']\n",
      "['DesicionTree8.txt', 'DesicionTree19.txt', 'DesicionTree25.txt', 'GuassianNaiveBayes5.txt', 'GuassianNaiveBayes12.txt', 'GuassianNaiveBayes28.txt', 'KNearestNeighbors9.txt', 'KNearestNeighbors13.txt', 'KNearestNeighbors29.txt', 'MultilayerPerceptron3.txt', 'MultilayerPerceptron11.txt', 'MultilayerPerceptron24.txt', 'RandomForestClassifier5.txt', 'RandomForestClassifier15.txt', 'RandomForestClassifier22.txt', 'SupportVectorMachine3.txt', 'SupportVectorMachine19.txt', 'SupportVectorMachine27.txt', 'Resnet18forDepthEstimation5.txt', 'Resnet18forImageSemanticSegmentation5.txt', 'VGGforImageSemanticSegmentation5.txt', 'VGGforObjectDetection4.txt', 'ViTforDepthEstimation2.txt', 'ViTforImageSemanticSegmentation9.txt', 'yolov8forImageSemanticSegmentation4.txt', 'yolov8forObjectDetection4.txt', 'BARTforTextClassification6.txt', 'BERTforTextClassification5.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def numerical_key(filename):\n",
    "    # Extract numbers from the filename\n",
    "    match = re.search(r'(\\d+)\\.txt$', filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "def find_shortest_files_in_batches(directory, model_types, batch_size=30):\n",
    "    shortest_files = []\n",
    "\n",
    "    # Process each model type\n",
    "    for model_type in model_types:\n",
    "        # Build the regular expression for filenames of the current model type\n",
    "        pattern = f\"{model_type}(\\\\d+)\\\\.txt$\"\n",
    "        # List all files matching the current model type\n",
    "        filenames = [f for f in os.listdir(directory) if re.search(pattern, f)]\n",
    "        # Sort files numerically\n",
    "        sorted_files = sorted(filenames, key=numerical_key)\n",
    "\n",
    "        # Process in batches\n",
    "        for i in range(0, len(sorted_files), batch_size):\n",
    "            min_length = float('inf')\n",
    "            shortest_file = None\n",
    "            current_batch = sorted_files[i:i+batch_size]\n",
    "            for filename in current_batch:\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                try:\n",
    "                    # Read the file and determine its length\n",
    "                    data_length = len(pd.read_csv(file_path, delimiter='\\t'))\n",
    "                    if data_length < min_length:\n",
    "                        min_length = data_length\n",
    "                        shortest_file = filename\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "            if shortest_file:\n",
    "                shortest_files.append(shortest_file)\n",
    "\n",
    "    return shortest_files\n",
    "\n",
    "# List of model types for 2 CPU core analysis\n",
    "model_type_2cpu = ['DesicionTree', 'GuassianNaiveBayes', 'KNearestNeighbors', 'MultilayerPerceptron', 'RandomForestClassifier', 'SupportVectorMachine']\n",
    "\n",
    "directory = './reanalyzed_data_2cpu/'\n",
    "shortest_files_list_2cpu = find_shortest_files_in_batches(directory, model_type_2cpu)\n",
    "print(shortest_files_list_2cpu)\n",
    "\n",
    "\n",
    "# List of model types for 8 CPU core analysis including additional deep learning models\n",
    "model_type_8cpu = ['DesicionTree', 'GuassianNaiveBayes', 'KNearestNeighbors', 'MultilayerPerceptron', 'RandomForestClassifier', 'SupportVectorMachine',\n",
    "                   'Resnet18forDepthEstimation', 'Resnet18forImageSemanticSegmentation', \n",
    "                   'VGGforImageSemanticSegmentation', 'VGGforObjectDetection',\n",
    "                   'ViTforDepthEstimation', 'ViTforImageSemanticSegmentation',\n",
    "                   'yolov8forImageSemanticSegmentation', 'yolov8forObjectDetection',\n",
    "                   'BARTforTextClassification', 'BERTforTextClassification']\n",
    "\n",
    "directory = './reanalyzed_data_8cpu/'\n",
    "shortest_files_list_8cpu = find_shortest_files_in_batches(directory, model_type_8cpu, batch_size = 10)\n",
    "print(shortest_files_list_8cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_columns = [\n",
    "    ['sectors_read', 'sectors_written', 'sectors_discarded'],\n",
    "    ['time_spent_reading_(ms)', 'time_spent_writing_(ms)', 'time_spent_discarding', 'time_spent_flushing'],\n",
    "    ['reads_completed_successfully', 'writes_completed', 'discards_completed_successfully', 'flush_requests_completed_successfully'],\n",
    "    ['reads_merged', 'writes_merged', 'discards_merged'],\n",
    "    ['I/Os_currently_in_progress', 'time_spent_doing_I/Os_(ms)', 'weighted_time_spent_doing_I/Os_(ms)']\n",
    "]\n",
    "\n",
    "standard_columns_2cpu = [['CPUUtilization'],\n",
    "                    ['Branches', 'Branches_CPU_Using', 'All_Branches_Using'], \n",
    "                    ['Branch_Misses', 'Branch_Misses_CPU_Using'], \n",
    "                    ['Cache_References', 'Cache_References_CPU_Using', 'All_Cache_Reference_Using'], \n",
    "                    ['Cache_Misses', 'Cache_Misses_CPU_Using'],\n",
    "                    ['Cycles', 'Cycles_CPU_Using'],\n",
    "                    ['Instructions', 'Instructions_CPU_Using', 'Instructions_per_CPU_Cycle'],\n",
    "                    ['Last_Level_Cache_Accesses', 'Last_Level_Cache_Accesses_CPU_Using'],\n",
    "                    ['Load_Dispatches', 'Load_Dispatches_CPU_Using'],\n",
    "                    ['Storage_Dispatches', 'Storage_Dispatches_CPU_Using'],\n",
    "                    ['AvgMHz-', 'AvgMHz0', 'AvgMHz1', 'AvgMHz2', 'AvgMHz3'],\n",
    "                    ['Busy-', 'Busy0', 'Busy1', 'Busy2', 'Busy3'], \n",
    "                    ['BzyMHz-', 'BzyMHz0', 'BzyMHz1', 'BzyMHz2', 'BzyMHz3'],\n",
    "                    ['C1-', 'C10', 'C11', 'C12', 'C13'], \n",
    "                    ['C2-', 'C20', 'C21', 'C22', 'C23'],\n",
    "                    ['CorWatt-', 'CorWatt0', 'CorWatt1', 'CorWatt2', 'CorWatt3'],\n",
    "                    ['PkgWatt-', 'PkgWatt0'], \n",
    "                    ['POLL-'], \n",
    "                    ['IRQ-', 'IRQ0', 'IRQ1', 'IRQ2', 'IRQ3'],               \n",
    "                    ['rxkB/s', 'rxpck/s', 'txkB/s', 'txpck/s', '%util'],\n",
    "                    ['TCP', 'UDP', 'UNIX', 'RAW', 'SCTP', 'DCCP']]\n",
    "\n",
    "standard_columns_8cpu = [['CPUUtilization'],\n",
    "                    ['Branches', 'Branches_CPU_Using', 'All_Branches_Using'], \n",
    "                    ['Branch_Misses', 'Branch_Misses_CPU_Using'], \n",
    "                    ['Cache_References', 'Cache_References_CPU_Using', 'All_Cache_Reference_Using'], \n",
    "                    ['Cache_Misses', 'Cache_Misses_CPU_Using'],\n",
    "                    ['Cycles', 'Cycles_CPU_Using'],\n",
    "                    ['Instructions', 'Instructions_CPU_Using', 'Instructions_per_CPU_Cycle'],\n",
    "                    ['Last_Level_Cache_Accesses', 'Last_Level_Cache_Accesses_CPU_Using'],\n",
    "                    ['Load_Dispatches', 'Load_Dispatches_CPU_Using'],\n",
    "                    ['Storage_Dispatches', 'Storage_Dispatches_CPU_Using'],\n",
    "                    ['AvgMHz-', 'AvgMHz0', 'AvgMHz1'], \n",
    "                    ['AvgMHz6', 'AvgMHz7', 'AvgMHz8', 'AvgMHz9'], \n",
    "                    ['AvgMHz10', 'AvgMHz11', 'AvgMHz12', 'AvgMHz13'],\n",
    "                    ['Busy-', 'Busy0', 'Busy1'], \n",
    "                    ['Busy6', 'Busy7', 'Busy8', 'Busy9'],\n",
    "                    ['Busy10', 'Busy11', 'Busy12', 'Busy13'], \n",
    "                    ['BzyMHz-', 'BzyMHz0', 'BzyMHz1'], \n",
    "                    ['BzyMHz6', 'BzyMHz7', 'BzyMHz8', 'BzyMHz9'], \n",
    "                    ['BzyMHz10', 'BzyMHz11', 'BzyMHz12', 'BzyMHz13'],\n",
    "                    ['C1-', 'C10', 'C11'], \n",
    "                    ['C16', 'C17', 'C18', 'C19'], \n",
    "                    ['C110', 'C111', 'C112', 'C113'], \n",
    "                    ['C2-', 'C20', 'C21'], \n",
    "                    ['C26', 'C27', 'C28', 'C29'], \n",
    "                    ['C210', 'C211', 'C212', 'C213'],\n",
    "                    ['CorWatt-', 'CorWatt0', 'CorWatt1'], \n",
    "                    ['CorWatt6', 'CorWatt7', 'CorWatt8', 'CorWatt9'], \n",
    "                    ['CorWatt10', 'CorWatt11', 'CorWatt12', 'CorWatt13'],\n",
    "                    ['POLL-'], \n",
    "                    ['IRQ-', 'IRQ0', 'IRQ1'], \n",
    "                    ['IRQ6', 'IRQ7', 'IRQ8', 'IRQ9'], \n",
    "                    ['IRQ10', 'IRQ11', 'IRQ12', 'IRQ13'],               \n",
    "                    ['rxkB/s', 'rxpck/s', 'txkB/s', 'txpck/s', '%util'],\n",
    "                    ['TCP', 'UDP', 'UNIX', 'RAW', 'SCTP', 'DCCP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_explanations_2cpu = {\n",
    "    # Disk operation metrics\n",
    "    'sectors_read': 'Number of sectors read from disk',\n",
    "    'sectors_written': 'Number of sectors written to disk',\n",
    "    'sectors_discarded': 'Number of sectors discarded from operations',\n",
    "    'time_spent_reading_(ms)': 'Time(ms) spent on reading operations',\n",
    "    'time_spent_writing_(ms)': 'Time(ms) spent on writing operations',\n",
    "    'time_spent_discarding': 'Time(ms) spent on discarding data',\n",
    "    'time_spent_flushing': 'Time(ms) spent on flushing data to storage',\n",
    "    'reads_completed_successfully': 'Number of read operations completed successfully',\n",
    "    'writes_completed': 'Number of write operations completed',\n",
    "    'discards_completed_successfully': 'Number of discard operations completed successfully',\n",
    "    'flush_requests_completed_successfully': 'Number of flush requests completed successfully',\n",
    "    'reads_merged': 'Number of read operations merged',\n",
    "    'writes_merged': 'Number of write operations merged',\n",
    "    'discards_merged': 'Number of discard operations merged',\n",
    "    'I/Os_currently_in_progress': 'Number of I/O operations currently in progress',\n",
    "    'time_spent_doing_I/Os_(ms)': 'Time(ms) spent on I/O operations',\n",
    "    'weighted_time_spent_doing_I/Os_(ms)': 'Weighted time(ms) spent on I/O operations',\n",
    "\n",
    "    # CPU utilization and performance metrics\n",
    "    'CPUUtilization': 'Percentage of CPU utilization',\n",
    "    'Branches': 'Total number of CPU branch instructions processed',\n",
    "    'Branches_CPU_Using': 'Branch instructions processed by the CPU',\n",
    "    'All_Branches_Using': 'All branches being used across CPUs',\n",
    "    'Branch_Misses': 'Number of branch instructions that the CPU failed to predict',\n",
    "    'Branch_Misses_CPU_Using': 'Branch misses on the CPU',\n",
    "    'Cache_References': 'Number of times the CPU cache was accessed',\n",
    "    'Cache_References_CPU_Using': 'Cache references by the CPU',\n",
    "    'All_Cache_Reference_Using': 'All cache references across CPUs',\n",
    "    'Cache_Misses': 'Number of failed cache attempts',\n",
    "    'Cache_Misses_CPU_Using': 'Cache misses by the CPU',\n",
    "    'Cycles': 'Total number of cycles',\n",
    "    'Cycles_CPU_Using': 'Cycles used by the CPU',\n",
    "    'Instructions': 'Total number of instructions executed',\n",
    "    'Instructions_CPU_Using': 'Instructions executed by the CPU',\n",
    "    'Instructions_per_CPU_Cycle': 'Number of instructions per CPU cycle',\n",
    "    'Last_Level_Cache_Accesses': 'Accesses to the last level cache',\n",
    "    'Last_Level_Cache_Accesses_CPU_Using': 'Last level cache accesses by the CPU',\n",
    "    'Load_Dispatches': 'Number of load dispatches',\n",
    "    'Load_Dispatches_CPU_Using': 'Load dispatches by the CPU',\n",
    "    'Storage_Dispatches': 'Number of storage dispatch operations',\n",
    "    'Storage_Dispatches_CPU_Using': 'Storage dispatch operations by the CPU',\n",
    "    'AvgMHz-': 'Average MHz across all CPUs',\n",
    "    'AvgMHz0': 'Average MHz for CPU 0',\n",
    "    'AvgMHz1': 'Average MHz for CPU 1',\n",
    "    'AvgMHz2': 'Average MHz for CPU 2',\n",
    "    'AvgMHz3': 'Average MHz for CPU 3',\n",
    "    'Busy-': 'Total busy time for all CPUs',\n",
    "    'Busy0': 'Busy time for CPU 0',\n",
    "    'Busy1': 'Busy time for CPU 1',\n",
    "    'Busy2': 'Busy time for CPU 2',\n",
    "    'Busy3': 'Busy time for CPU 3',\n",
    "    'BzyMHz-': 'Busy MHz across all CPUs',\n",
    "    'BzyMHz0': 'Busy MHz for CPU 0',\n",
    "    'BzyMHz1': 'Busy MHz for CPU 1',\n",
    "    'BzyMHz2': 'Busy MHz for CPU 2',\n",
    "    'BzyMHz3': 'Busy MHz for CPU 3',\n",
    "    'C1-': 'Time spent in CPU power state C1 across all CPUs',\n",
    "    'C10': 'Time spent in power state C1 for CPU 0',\n",
    "    'C11': 'Time spent in power state C1 for CPU 1',\n",
    "    'C12': 'Time spent in power state C1 for CPU 2',\n",
    "    'C13': 'Time spent in power state C1 for CPU 3',\n",
    "    'C2-': 'Time spent in CPU power state C2 across all CPUs',\n",
    "    'C20': 'Time spent in power state C2 for CPU 0',\n",
    "    'C21': 'Time spent in power state C2 for CPU 1',\n",
    "    'C22': 'Time spent in power state C2 for CPU 2',\n",
    "    'C23': 'Time spent in power state C2 for CPU 3',\n",
    "    'CorWatt-': 'Core wattage usage across all CPUs',\n",
    "    'CorWatt0': 'Core wattage for CPU 0',\n",
    "    'CorWatt1': 'Core wattage for CPU 1',\n",
    "    'CorWatt2': 'Core wattage for CPU 2',\n",
    "    'CorWatt3': 'Core wattage for CPU 3',\n",
    "    'PkgWatt-': 'Package wattage across all CPUs',\n",
    "    'PkgWatt0': 'Package wattage for CPU 0',\n",
    "    'POLL-': 'Polling time across all CPUs',\n",
    "    'IRQ-': 'Interrupt request time across all CPUs',\n",
    "    'IRQ0': 'Interrupt request time for CPU 0',\n",
    "    'IRQ1': 'Interrupt request time for CPU 1',\n",
    "    'IRQ2': 'Interrupt request time for CPU 2',\n",
    "    'IRQ3': 'Interrupt request time for CPU 3',\n",
    "    'rxkB/s': 'Received kilobytes per second',\n",
    "    'rxpck/s': 'Received packets per second',\n",
    "    'txkB/s': 'Transmitted kilobytes per second',\n",
    "    'txpck/s': 'Transmitted packets per second',\n",
    "    '%util': 'Percentage of network utilization',\n",
    "    'TCP': 'Transmission Control Protocol connections',\n",
    "    'UDP': 'User Datagram Protocol connections',\n",
    "    'UNIX': 'UNIX socket connections',\n",
    "    'RAW': 'Raw socket connections',\n",
    "    'SCTP': 'Stream Control Transmission Protocol connections',\n",
    "    'DCCP': 'Datagram Congestion Control Protocol connections'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_explanations_8cpu = {\n",
    "    # Common CPU performance metrics\n",
    "    'CPUUtilization': 'Percentage of CPU utilization',\n",
    "    'Branches': 'Total number of CPU branch instructions processed',\n",
    "    'Branches_CPU_Using': 'Branch instructions processed by the CPU',\n",
    "    'All_Branches_Using': 'All branches being used across CPUs',\n",
    "    'Branch_Misses': 'Number of branch instructions that the CPU failed to predict',\n",
    "    'Branch_Misses_CPU_Using': 'Branch misses on the CPU',\n",
    "    'Cache_References': 'Number of times the CPU cache was accessed',\n",
    "    'Cache_References_CPU_Using': 'Cache references by the CPU',\n",
    "    'All_Cache_Reference_Using': 'All cache references across CPUs',\n",
    "    'Cache_Misses': 'Number of failed cache attempts',\n",
    "    'Cache_Misses_CPU_Using': 'Cache misses by the CPU',\n",
    "    'Cycles': 'Total number of cycles',\n",
    "    'Cycles_CPU_Using': 'Cycles used by the CPU',\n",
    "    'Instructions': 'Total number of instructions executed',\n",
    "    'Instructions_CPU_Using': 'Instructions executed by the CPU',\n",
    "    'Instructions_per_CPU_Cycle': 'Number of instructions per CPU cycle',\n",
    "    'Last_Level_Cache_Accesses': 'Accesses to the last level cache',\n",
    "    'Last_Level_Cache_Accesses_CPU_Using': 'Last level cache accesses by the CPU',\n",
    "    'Load_Dispatches': 'Number of load dispatches',\n",
    "    'Load_Dispatches_CPU_Using': 'Load dispatches by the CPU',\n",
    "    'Storage_Dispatches': 'Number of storage dispatch operations',\n",
    "    'Storage_Dispatches_CPU_Using': 'Storage dispatch operations by the CPU',\n",
    "\n",
    "    # Enhanced metrics for multi-core CPUs\n",
    "    'AvgMHz-': 'Average MHz across all CPUs',\n",
    "    'Busy-': 'Total busy time for all CPUs',\n",
    "    'BzyMHz-': 'Busy MHz across all CPUs',\n",
    "    'CorWatt-': 'Core wattage usage across all CPUs',\n",
    "    'PkgWatt-': 'Package wattage across all CPUs',\n",
    "    'PkgWatt0': 'Package wattage for CPU 0',\n",
    "    'POLL-': 'Polling time across all CPUs',\n",
    "    'IRQ-': 'Interrupt request time across all CPUs',\n",
    "    'rxkB/s': 'Received kilobytes per second',\n",
    "    'rxpck/s': 'Received packets per second',\n",
    "    'txkB/s': 'Transmitted kilobytes per second',\n",
    "    'txpck/s': 'Transmitted packets per second',\n",
    "    '%util': 'Percentage of network utilization',\n",
    "    'TCP': 'Transmission Control Protocol connections',\n",
    "    'UDP': 'User Datagram Protocol connections',\n",
    "    'UNIX': 'UNIX socket connections',\n",
    "    'RAW': 'Raw socket connections',\n",
    "    'SCTP': 'Stream Control Transmission Protocol connections',\n",
    "    'DCCP': 'Datagram Congestion Control Protocol connections',\n",
    "\n",
    "    # Specific CPU core metrics (general pattern)\n",
    "    **{f'AvgMHz{i}': f'Average MHz for CPU {i}' for i in range(14) if i not in range(2, 6)},\n",
    "    **{f'Busy{i}': f'Busy time for CPU {i}' for i in range(14) if i not in range(2, 6)},\n",
    "    **{f'BzyMHz{i}': f'Busy MHz for CPU {i}' for i in range(14) if i not in range(2, 6)},\n",
    "    **{f'IRQ{i}': f'Interrupt request time for CPU {i}' for i in range(14) if i not in range(2, 6)},\n",
    "    **{f'CorWatt{i}': f'Core wattage for CPU {i}' for i in range(14) if i not in range(2, 6)},\n",
    "    **{f'C1{i}': f'Time spent in power state C1 for CPU {i}' for i in range(14) if i not in range(4, 6)},\n",
    "    **{f'C2{i}': f'Time spent in power state C2 for CPU {i}' for i in range(14) if i not in range(4, 6)},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = './saved_plots_2cpu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "# Create a PowerPoint presentation object\n",
    "prs = Presentation()\n",
    "\n",
    "def insert_figures_into_pptx(plot_filename, slide, top):\n",
    "    # Calculate the left margin to center the image\n",
    "    # Assuming standard slide size and image width\n",
    "    image_width = Inches(9.6)\n",
    "    slide_width = Inches(10)  # Typical width for a standard slide\n",
    "    left = (slide_width - image_width) / 2  # Center the image horizontally\n",
    "\n",
    "    # Add the image\n",
    "    pic = slide.shapes.add_picture(plot_filename, left, top, width=image_width)  # Adjust width as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cycler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Define color cycles for primary and secondary y-axes\n",
    "default_cycler = cycler('color', plt.cm.tab10.colors)\n",
    "secondary_cycler = cycler('color', plt.cm.Set2.colors)\n",
    "\n",
    "directory = './reanalyzed_data_2cpu/'\n",
    "\n",
    "# Define a larger fontsize for better readability\n",
    "fontsize = 14  # You can adjust this value as needed\n",
    "\n",
    "for filename in shortest_files_list_2cpu:\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        data = pd.read_csv(file_path, delimiter='\\t')\n",
    "        data.ffill(inplace=True)  # Forward fill to handle missing data\n",
    "\n",
    "        # Prepare filename for display in titles\n",
    "        base_filename = filename.replace('.txt', '')\n",
    "\n",
    "        # Convert timestamps and calculate elapsed seconds\n",
    "        data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "        data['Seconds'] = (data['Timestamp'] - data['Timestamp'].iloc[0]).dt.total_seconds()\n",
    "\n",
    "        figure_count = 0\n",
    "        figures_per_slide = 3\n",
    "        slide_height = Inches(7.5)  # Typical height for content in a standard slide\n",
    "        figure_height = Inches(2.4)  # Height each figure takes, including some padding\n",
    "\n",
    "        # Adding a title slide for the file\n",
    "        title_slide_layout = prs.slide_layouts[0]  # Assuming layout 0 is the title slide layout\n",
    "        slide = prs.slides.add_slide(title_slide_layout)\n",
    "        title = slide.shapes.title\n",
    "        title.text = f\"Report for {filename.replace('.txt', '')} (run in a VM with 2 vCPU)\"\n",
    "\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "\n",
    "        for group in standard_columns_2cpu:\n",
    "            fig, ax1 = plt.subplots(figsize=(20, 5))\n",
    "            ax1.set_prop_cycle(default_cycler)  # Set color cycle for primary axis\n",
    "\n",
    "            # Check if secondary axis is needed\n",
    "            secondary_y_needed = any('using' in col.lower() or '%' in col for col in group)\n",
    "\n",
    "            if secondary_y_needed:\n",
    "                ax2 = ax1.twinx()\n",
    "                ax2.set_ylim(0, 100)\n",
    "                ax2.set_ylabel('Percentage', fontsize=fontsize)\n",
    "                ax2.set_prop_cycle(secondary_cycler)  # Set color cycle for secondary axis\n",
    "\n",
    "            for column in group:\n",
    "                if column in data.columns:\n",
    "                    if 'using' in column.lower() or '%' in column:\n",
    "                        # Plot on secondary y-axis if column involves percentages or specific usage\n",
    "                        ax2.plot(data['Seconds'], data[column], label=column_explanations_2cpu.get(column, column), marker='.')\n",
    "                    else:\n",
    "                        # Plot on primary y-axis\n",
    "                        ax1.plot(data['Seconds'], data[column], label=column_explanations_2cpu.get(column, column), marker='.')\n",
    "\n",
    "            # Configure legends to display all labels\n",
    "            lines, labels = ax1.get_legend_handles_labels()\n",
    "            if secondary_y_needed:\n",
    "                lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "                ax2.legend(lines + lines2, labels + labels2, loc='upper left', fontsize=fontsize)\n",
    "            else:\n",
    "                ax1.legend(fontsize=fontsize)\n",
    "\n",
    "            # Set titles using the description dictionary\n",
    "            title_text = ('Performance Metrics: ' + ', '.join([column_explanations_2cpu.get(col, col) for col in group]) + ' in ' + base_filename).replace('_', ' ')\n",
    "            wrapped_title = textwrap.fill(title_text, width = 140)\n",
    "            plt.title(wrapped_title, fontsize=fontsize)\n",
    "            ax1.set_xlabel('Time (s)', fontsize=fontsize)\n",
    "            ax1.set_ylabel('Value', fontsize=fontsize)\n",
    "            ax1.grid(True)\n",
    "\n",
    "            ax1.tick_params(axis='both', labelsize=fontsize)\n",
    "            if secondary_y_needed:\n",
    "                ax2.tick_params(axis='both', labelsize=fontsize)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # plt.show()\n",
    "            save_path = save_directory + ''.join(group).replace(' ', '').replace('/', '') + '_' + base_filename + '.jpg'\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "            # Calculate vertical positioning based on the count\n",
    "            current_top = Inches(0.3) + (figure_height * (figure_count % figures_per_slide))\n",
    "\n",
    "            if figure_count % figures_per_slide == 0 and figure_count != 0:  # Check if the current slide is full\n",
    "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "                current_top = Inches(0.3)  # Reset position for the new slide\n",
    "\n",
    "            insert_figures_into_pptx(save_path, slide, current_top)\n",
    "            figure_count += 1\n",
    "\n",
    "        for group in diff_columns:\n",
    "            fig, ax = plt.subplots(figsize=(20, 5))\n",
    "            ax.set_prop_cycle(default_cycler)\n",
    "\n",
    "            # Calculate and plot the difference of each metric\n",
    "            for column in group:\n",
    "                if column in data.columns:\n",
    "                    diff = data[column].diff() + 1  # Calculate difference and plot from the second point to avoid NaN\n",
    "                    ax.plot(data['Seconds'][1:], diff[1:], label=f'Delta {column_explanations_2cpu.get(column, column)}', marker='.', linestyle='-')\n",
    "\n",
    "            ax.set_yscale('log')\n",
    "            ax.legend(fontsize=fontsize)\n",
    "            title_text = ('Performance Metrics: Delta ' + ', '.join([column_explanations_2cpu.get(col, col) for col in group]) + ' in ' + base_filename).replace('_', ' ')\n",
    "            wrapped_title = textwrap.fill(title_text, width = 140)\n",
    "            plt.title(wrapped_title, fontsize=fontsize)\n",
    "            ax.set_xlabel('Time (s)', fontsize=fontsize)\n",
    "            ax.set_ylabel('Delta Value', fontsize=fontsize)\n",
    "            ax.grid(True)\n",
    "            ax.tick_params(axis='both', labelsize=fontsize)\n",
    "            plt.tight_layout()\n",
    "            # plt.show()\n",
    "            save_path = save_directory + ''.join(group).replace(' ', '').replace('/', '') + '_' + base_filename + '.jpg'\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "            \n",
    "            # Calculate vertical positioning based on the count\n",
    "            current_top = Inches(0.3) + (figure_height * (figure_count % figures_per_slide))\n",
    "\n",
    "            if figure_count % figures_per_slide == 0 and figure_count != 0:  # Check if the current slide is full\n",
    "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "                current_top = Inches(0.3)  # Reset position for the new slide\n",
    "\n",
    "            insert_figures_into_pptx(save_path, slide, current_top)\n",
    "            figure_count += 1\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the presentation\n",
    "prs.save('performance_metrics_presentation_2cpu.pptx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = './saved_plots_8cpu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "# Create a PowerPoint presentation object\n",
    "prs = Presentation()\n",
    "\n",
    "def insert_figures_into_pptx(plot_filename, slide, top):\n",
    "    # Calculate the left margin to center the image\n",
    "    # Assuming standard slide size and image width\n",
    "    image_width = Inches(8)\n",
    "    slide_width = Inches(10)  # Typical width for a standard slide\n",
    "    left = (slide_width - image_width) / 2  # Center the image horizontally\n",
    "\n",
    "    # Add the image\n",
    "    pic = slide.shapes.add_picture(plot_filename, left, top, width=image_width)  # Adjust width as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cycler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Define color cycles for primary and secondary y-axes\n",
    "default_cycler = cycler('color', plt.cm.tab10.colors)\n",
    "secondary_cycler = cycler('color', plt.cm.Set2.colors)\n",
    "\n",
    "directory = './reanalyzed_data_8cpu/'\n",
    "\n",
    "# Define a larger fontsize for better readability\n",
    "fontsize = 34  # You can adjust this value as needed\n",
    "\n",
    "for filename in shortest_files_list_8cpu[0, 17]:\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        data = pd.read_csv(file_path, delimiter='\\t')\n",
    "        data.ffill(inplace=True)  # Forward fill to handle missing data\n",
    "\n",
    "        # Prepare filename for display in titles\n",
    "        base_filename = filename.replace('.txt', '')\n",
    "\n",
    "        # Convert timestamps and calculate elapsed seconds\n",
    "        data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "        data['Seconds'] = (data['Timestamp'] - data['Timestamp'].iloc[0]).dt.total_seconds()\n",
    "\n",
    "        figure_count = 0\n",
    "        figures_per_slide = 7\n",
    "        slide_height = Inches(7.5)  # Typical height for content in a standard slide\n",
    "        figure_height = Inches(1)  # Height each figure takes, including some padding\n",
    "\n",
    "        # Adding a title slide for the file\n",
    "        title_slide_layout = prs.slide_layouts[0]  # Assuming layout 0 is the title slide layout\n",
    "        slide = prs.slides.add_slide(title_slide_layout)\n",
    "        title = slide.shapes.title\n",
    "        title.text = f\"Report for {filename.replace('.txt', '')} (run in a VM with 8 vCPU)\"\n",
    "\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "\n",
    "        for group in standard_columns_8cpu:\n",
    "            fig, ax1 = plt.subplots(figsize=(40, 5))\n",
    "            ax1.set_prop_cycle(default_cycler)  # Set color cycle for primary axis\n",
    "\n",
    "            # Check if secondary axis is needed\n",
    "            secondary_y_needed = any('using' in col.lower() or '%' in col for col in group)\n",
    "\n",
    "            if secondary_y_needed:\n",
    "                ax2 = ax1.twinx()\n",
    "                ax2.set_ylim(0, 100)\n",
    "                ax2.set_ylabel('Percentage', fontsize=fontsize)\n",
    "                ax2.set_prop_cycle(secondary_cycler)  # Set color cycle for secondary axis\n",
    "\n",
    "            for column in group:\n",
    "                if column in data.columns:\n",
    "                    if 'using' in column.lower() or '%' in column:\n",
    "                        # Plot on secondary y-axis if column involves percentages or specific usage\n",
    "                        ax2.plot(data['Seconds'], data[column], label=column_explanations_8cpu.get(column, column), marker='.')\n",
    "                    else:\n",
    "                        # Plot on primary y-axis\n",
    "                        ax1.plot(data['Seconds'], data[column], label=column_explanations_8cpu.get(column, column), marker='.')\n",
    "\n",
    "            # Configure legends to display all labels\n",
    "            lines, labels = ax1.get_legend_handles_labels()\n",
    "            if secondary_y_needed:\n",
    "                lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "                ax2.legend(lines + lines2, labels + labels2, loc='upper left', fontsize=fontsize)\n",
    "            else:\n",
    "                ax1.legend(fontsize=fontsize)\n",
    "\n",
    "            # Set titles using the description dictionary\n",
    "            title_text = ('Performance Metrics: ' + ', '.join([column_explanations_8cpu.get(col, col) for col in group]) + ' in ' + base_filename).replace('_', ' ')\n",
    "            wrapped_title = textwrap.fill(title_text, width = 140)\n",
    "            plt.title(wrapped_title, fontsize=fontsize)\n",
    "            ax1.set_xlabel('Time (s)', fontsize=fontsize)\n",
    "            ax1.set_ylabel('Value', fontsize=fontsize)\n",
    "            ax1.grid(True)\n",
    "\n",
    "            ax1.tick_params(axis='both', labelsize=fontsize)\n",
    "            if secondary_y_needed:\n",
    "                ax2.tick_params(axis='both', labelsize=fontsize)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # plt.show()\n",
    "            save_path = save_directory + ''.join(group).replace(' ', '').replace('/', '') + '_' + base_filename + '.jpg'\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "            # Calculate vertical positioning based on the count\n",
    "            current_top = Inches(0.1) + (figure_height * (figure_count % figures_per_slide))\n",
    "\n",
    "            if figure_count % figures_per_slide == 0 and figure_count != 0:  # Check if the current slide is full\n",
    "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "                current_top = Inches(0.1)  # Reset position for the new slide\n",
    "\n",
    "            insert_figures_into_pptx(save_path, slide, current_top)\n",
    "            figure_count += 1\n",
    "\n",
    "        for group in diff_columns:\n",
    "            fig, ax = plt.subplots(figsize=(40, 5))\n",
    "            ax.set_prop_cycle(default_cycler)\n",
    "\n",
    "            # Calculate and plot the difference of each metric\n",
    "            for column in group:\n",
    "                if column in data.columns:\n",
    "                    diff = data[column].diff() + 1  # Calculate difference and plot from the second point to avoid NaN\n",
    "                    ax.plot(data['Seconds'][1:], diff[1:], label=f'Delta {column_explanations_8cpu.get(column, column)}', marker='.', linestyle='-')\n",
    "\n",
    "            ax.set_yscale('log')\n",
    "            ax.legend(fontsize=fontsize)\n",
    "            title_text = ('Performance Metrics: Delta ' + ', '.join([column_explanations_8cpu.get(col, col) for col in group]) + ' in ' + base_filename).replace('_', ' ')\n",
    "            wrapped_title = textwrap.fill(title_text, width = 140)\n",
    "            plt.title(wrapped_title, fontsize=fontsize)\n",
    "            ax.set_xlabel('Time (s)', fontsize=fontsize)\n",
    "            ax.set_ylabel('Delta Value', fontsize=fontsize)\n",
    "            ax.grid(True)\n",
    "            ax.tick_params(axis='both', labelsize=fontsize)\n",
    "            plt.tight_layout()\n",
    "            # plt.show()\n",
    "            save_path = save_directory + ''.join(group).replace(' ', '').replace('/', '') + '_' + base_filename + '.jpg'\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "            \n",
    "            # Calculate vertical positioning based on the count\n",
    "            current_top = Inches(0) + (figure_height * (figure_count % figures_per_slide))\n",
    "\n",
    "            if figure_count % figures_per_slide == 0 and figure_count != 0:  # Check if the current slide is full\n",
    "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "                current_top = Inches(0.1)  # Reset position for the new slide\n",
    "\n",
    "            insert_figures_into_pptx(save_path, slide, current_top)\n",
    "            figure_count += 1\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the presentation\n",
    "prs.save('performance_metrics_presentation_8cpu_1.pptx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = './saved_plots_8cpu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "# Create a PowerPoint presentation object\n",
    "prs = Presentation()\n",
    "\n",
    "def insert_figures_into_pptx(plot_filename, slide, top):\n",
    "    # Calculate the left margin to center the image\n",
    "    # Assuming standard slide size and image width\n",
    "    image_width = Inches(8)\n",
    "    slide_width = Inches(10)  # Typical width for a standard slide\n",
    "    left = (slide_width - image_width) / 2  # Center the image horizontally\n",
    "\n",
    "    # Add the image\n",
    "    pic = slide.shapes.add_picture(plot_filename, left, top, width=image_width)  # Adjust width as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cycler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Define color cycles for primary and secondary y-axes\n",
    "default_cycler = cycler('color', plt.cm.tab10.colors)\n",
    "secondary_cycler = cycler('color', plt.cm.Set2.colors)\n",
    "\n",
    "directory = './reanalyzed_data_8cpu/'\n",
    "\n",
    "# Define a larger fontsize for better readability\n",
    "fontsize = 34  # You can adjust this value as needed\n",
    "\n",
    "for filename in shortest_files_list_8cpu[18:]:\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        data = pd.read_csv(file_path, delimiter='\\t')\n",
    "        data.ffill(inplace=True)  # Forward fill to handle missing data\n",
    "\n",
    "        # Prepare filename for display in titles\n",
    "        base_filename = filename.replace('.txt', '')\n",
    "\n",
    "        # Convert timestamps and calculate elapsed seconds\n",
    "        data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "        data['Seconds'] = (data['Timestamp'] - data['Timestamp'].iloc[0]).dt.total_seconds()\n",
    "\n",
    "        figure_count = 0\n",
    "        figures_per_slide = 7\n",
    "        slide_height = Inches(7.5)  # Typical height for content in a standard slide\n",
    "        figure_height = Inches(1)  # Height each figure takes, including some padding\n",
    "\n",
    "        # Adding a title slide for the file\n",
    "        title_slide_layout = prs.slide_layouts[0]  # Assuming layout 0 is the title slide layout\n",
    "        slide = prs.slides.add_slide(title_slide_layout)\n",
    "        title = slide.shapes.title\n",
    "        title.text = f\"Report for {filename.replace('.txt', '')} (run in a VM with 8 vCPU)\"\n",
    "\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "\n",
    "        for group in standard_columns_8cpu:\n",
    "            fig, ax1 = plt.subplots(figsize=(40, 5))\n",
    "            ax1.set_prop_cycle(default_cycler)  # Set color cycle for primary axis\n",
    "\n",
    "            # Check if secondary axis is needed\n",
    "            secondary_y_needed = any('using' in col.lower() or '%' in col for col in group)\n",
    "\n",
    "            if secondary_y_needed:\n",
    "                ax2 = ax1.twinx()\n",
    "                ax2.set_ylim(0, 100)\n",
    "                ax2.set_ylabel('Percentage', fontsize=fontsize)\n",
    "                ax2.set_prop_cycle(secondary_cycler)  # Set color cycle for secondary axis\n",
    "\n",
    "            for column in group:\n",
    "                if column in data.columns:\n",
    "                    if 'using' in column.lower() or '%' in column:\n",
    "                        # Plot on secondary y-axis if column involves percentages or specific usage\n",
    "                        ax2.plot(data['Seconds'], data[column], label=column_explanations_8cpu.get(column, column), marker='.')\n",
    "                    else:\n",
    "                        # Plot on primary y-axis\n",
    "                        ax1.plot(data['Seconds'], data[column], label=column_explanations_8cpu.get(column, column), marker='.')\n",
    "\n",
    "            # Configure legends to display all labels\n",
    "            lines, labels = ax1.get_legend_handles_labels()\n",
    "            if secondary_y_needed:\n",
    "                lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "                ax2.legend(lines + lines2, labels + labels2, loc='upper left', fontsize=fontsize)\n",
    "            else:\n",
    "                ax1.legend(fontsize=fontsize)\n",
    "\n",
    "            # Set titles using the description dictionary\n",
    "            title_text = ('Performance Metrics: ' + ', '.join([column_explanations_8cpu.get(col, col) for col in group]) + ' in ' + base_filename).replace('_', ' ')\n",
    "            wrapped_title = textwrap.fill(title_text, width = 140)\n",
    "            plt.title(wrapped_title, fontsize=fontsize)\n",
    "            ax1.set_xlabel('Time (s)', fontsize=fontsize)\n",
    "            ax1.set_ylabel('Value', fontsize=fontsize)\n",
    "            ax1.grid(True)\n",
    "\n",
    "            ax1.tick_params(axis='both', labelsize=fontsize)\n",
    "            if secondary_y_needed:\n",
    "                ax2.tick_params(axis='both', labelsize=fontsize)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # plt.show()\n",
    "            save_path = save_directory + ''.join(group).replace(' ', '').replace('/', '') + '_' + base_filename + '.jpg'\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "            # Calculate vertical positioning based on the count\n",
    "            current_top = Inches(0.1) + (figure_height * (figure_count % figures_per_slide))\n",
    "\n",
    "            if figure_count % figures_per_slide == 0 and figure_count != 0:  # Check if the current slide is full\n",
    "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "                current_top = Inches(0.1)  # Reset position for the new slide\n",
    "\n",
    "            insert_figures_into_pptx(save_path, slide, current_top)\n",
    "            figure_count += 1\n",
    "\n",
    "        for group in diff_columns:\n",
    "            fig, ax = plt.subplots(figsize=(40, 5))\n",
    "            ax.set_prop_cycle(default_cycler)\n",
    "\n",
    "            # Calculate and plot the difference of each metric\n",
    "            for column in group:\n",
    "                if column in data.columns:\n",
    "                    diff = data[column].diff() + 1  # Calculate difference and plot from the second point to avoid NaN\n",
    "                    ax.plot(data['Seconds'][1:], diff[1:], label=f'Delta {column_explanations_8cpu.get(column, column)}', marker='.', linestyle='-')\n",
    "\n",
    "            ax.set_yscale('log')\n",
    "            ax.legend(fontsize=fontsize)\n",
    "            title_text = ('Performance Metrics: Delta ' + ', '.join([column_explanations_8cpu.get(col, col) for col in group]) + ' in ' + base_filename).replace('_', ' ')\n",
    "            wrapped_title = textwrap.fill(title_text, width = 140)\n",
    "            plt.title(wrapped_title, fontsize=fontsize)\n",
    "            ax.set_xlabel('Time (s)', fontsize=fontsize)\n",
    "            ax.set_ylabel('Delta Value', fontsize=fontsize)\n",
    "            ax.grid(True)\n",
    "            ax.tick_params(axis='both', labelsize=fontsize)\n",
    "            plt.tight_layout()\n",
    "            # plt.show()\n",
    "            save_path = save_directory + ''.join(group).replace(' ', '').replace('/', '') + '_' + base_filename + '.jpg'\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "            \n",
    "            # Calculate vertical positioning based on the count\n",
    "            current_top = Inches(0) + (figure_height * (figure_count % figures_per_slide))\n",
    "\n",
    "            if figure_count % figures_per_slide == 0 and figure_count != 0:  # Check if the current slide is full\n",
    "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "                current_top = Inches(0.1)  # Reset position for the new slide\n",
    "\n",
    "            insert_figures_into_pptx(save_path, slide, current_top)\n",
    "            figure_count += 1\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the presentation\n",
    "prs.save('performance_metrics_presentation_8cpu_2.pptx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
